# F√≥rmulas del An√°lisis de Sentimiento y Categorizaci√≥n

Este documento describe las f√≥rmulas matem√°ticas y m√©todos utilizados en SentimentInsightUAM_SA para el an√°lisis de opiniones de profesores.

---

## üìä 1. An√°lisis de Sentimiento General (BERT)

### 1.1 Modelo Base
Se utiliza un modelo BERT pre-entrenado para clasificaci√≥n de secuencias:

- **Modelo por defecto**: `finiteautomata/beto-sentiment-analysis`
- **Arquitectura**: BERT con capa de clasificaci√≥n de 3 clases

### 1.2 Clasificaci√≥n Softmax

El modelo BERT produce logits que se transforman en probabilidades usando **softmax**:

$$
P(clase_i) = \frac{e^{z_i}}{\sum_{j=1}^{3} e^{z_j}}
$$

Donde:
- $z_i$ = logit de la clase $i$
- $P(clase_i)$ = probabilidad de la clase $i$ (positivo, neutral, negativo)

#### Prop√≥sito del C√°lculo

El resultado del modelo BERT nos proporciona:

1. **Clasificaci√≥n autom√°tica**: Determina si una opini√≥n de un profesor es positiva, neutral o negativa sin intervenci√≥n manual.

2. **Medici√≥n de confianza**: El score de confianza indica qu√© tan seguro est√° el modelo de su predicci√≥n, permitiendo identificar opiniones ambiguas que podr√≠an requerir revisi√≥n manual.

3. **Distribuci√≥n de probabilidades (pesos)**: Los pesos normalizados permiten:
   - Calcular estad√≠sticas agregadas ponderadas por confianza
   - Generar visualizaciones de distribuci√≥n de sentimientos
   - Identificar tendencias generales en las opiniones de profesores/cursos
   - Comparar la percepci√≥n entre diferentes profesores o materias

4. **An√°lisis temporal**: Al procesar opiniones con fechas, se pueden detectar cambios en la percepci√≥n de un profesor a lo largo del tiempo.

### 1.3 C√°lculo de Pesos por Clase

Cuando el modelo retorna solo la clase ganadora y su confianza, los pesos se distribuyen as√≠:

$$
peso_{ganador} = confianza
$$

$$
peso_{otros} = \frac{1 - confianza}{2}
$$

### 1.4 Normalizaci√≥n de Pesos

Los pesos se normalizan para sumar 1:

$$
peso_{normalizado_i} = \frac{peso_i}{\sum_{j} peso_j}
$$

---

## üè∑Ô∏è 2. Categorizaci√≥n por Palabras Clave

### 2.1 Sistema de Categor√≠as

El categorizador clasifica opiniones en **tres dimensiones**:

| Categor√≠a | Descripci√≥n |
|-----------|-------------|
| **Calidad Did√°ctica** | Eval√∫a habilidades de ense√±anza, claridad, dominio del tema |
| **M√©todo de Evaluaci√≥n** | Eval√∫a justicia, dificultad, criterios de calificaci√≥n |
| **Empat√≠a** | Eval√∫a trato humano, accesibilidad, flexibilidad |

#### Prop√≥sito de la Categorizaci√≥n

La categorizaci√≥n por palabras clave permite:

1. **An√°lisis multidimensional**: A diferencia del sentimiento general, esta t√©cnica desglosa la opini√≥n en aspectos espec√≠ficos del desempe√±o docente.

2. **Identificaci√≥n de fortalezas/debilidades**: Un profesor puede tener alta calidad did√°ctica pero baja empat√≠a, lo cual no se detectar√≠a solo con sentimiento general.

3. **Retroalimentaci√≥n espec√≠fica**: Las instituciones pueden generar reportes detallados para mejorar √°reas espec√≠ficas.

4. **Comparaci√≥n por dimensi√≥n**: Permite comparar profesores/cursos en cada dimensi√≥n independientemente.

### 2.2 F√≥rmula de Score por Categor√≠a

Para cada categor√≠a (calidad did√°ctica, m√©todo de evaluaci√≥n, empat√≠a), se realiza el siguiente proceso:

#### Paso 1: Conteo de Palabras Clave

Se buscan en el texto todas las palabras/frases del diccionario de palabras clave:

$$
n_{pos} = \sum_{i=1}^{k_{pos}} \mathbb{1}(palabra\_positiva_i \in texto)
$$

$$
n_{neg} = \sum_{i=1}^{k_{neg}} \mathbb{1}(palabra\_negativa_i \in texto)
$$

Donde:
- $n_{pos}$ = cantidad de palabras positivas encontradas
- $n_{neg}$ = cantidad de palabras negativas encontradas
- $k_{pos}$, $k_{neg}$ = tama√±o de los diccionarios positivo y negativo
- $\mathbb{1}(\cdot)$ = funci√≥n indicadora (1 si la condici√≥n es verdadera, 0 si no)

#### Paso 2: C√°lculo del Total

$$
n_{total} = n_{pos} + n_{neg}
$$

### 2.3 Score Positivo

El score positivo representa la proporci√≥n de palabras positivas respecto al total encontrado:

$$
score_{positivo} = \frac{n_{pos}}{n_{total}} = \frac{n_{pos}}{n_{pos} + n_{neg}}
$$

Este score var√≠a de 0 a 1:
- **score = 1.0**: Solo se encontraron palabras positivas
- **score = 0.5**: Balance entre palabras positivas y negativas
- **score = 0.0**: Solo se encontraron palabras negativas

### 2.4 Reglas de Clasificaci√≥n

La valoraci√≥n se determina seg√∫n umbrales:

| Condici√≥n | Valoraci√≥n | Confianza |
|-----------|------------|-----------|
| $score_{positivo} > 0.6$ | positivo | $score_{positivo}$ |
| $score_{positivo} < 0.4$ | negativo | $1 - score_{positivo}$ |
| $0.4 \leq score_{positivo} \leq 0.6$ | neutral | $0.5$ |
| $n_{total} = 0$ | neutral | $0.5$ |

### 2.5 F√≥rmula Combinada

La f√≥rmula completa para determinar la valoraci√≥n en cada categor√≠a es:

$$
valoracion = 
\begin{cases}
\text{positivo} & \text{si } \frac{n_{pos}}{n_{total}} > 0.6 \\
\text{negativo} & \text{si } \frac{n_{pos}}{n_{total}} < 0.4 \\
\text{neutral} & \text{si } 0.4 \leq \frac{n_{pos}}{n_{total}} \leq 0.6 \\
\text{neutral} & \text{si } n_{total} = 0 \text{ (sin palabras clave)}
\end{cases}
$$

### 2.6 C√°lculo de Confianza por Categor√≠a

La confianza indica qu√© tan segura es la clasificaci√≥n:

$$
confianza = 
\begin{cases}
score_{positivo} & \text{si valoraci√≥n = positivo} \\
1 - score_{positivo} & \text{si valoraci√≥n = negativo} \\
0.5 & \text{si valoraci√≥n = neutral}
\end{cases}
$$

**Interpretaci√≥n de la confianza**:
- **Alta confianza (>0.8)**: La opini√≥n tiene palabras clave claramente predominantes en una direcci√≥n.
- **Confianza media (0.6-0.8)**: Predomina una polaridad pero hay presencia de la opuesta.
- **Confianza baja (0.5)**: Neutral por falta de palabras clave o balance exacto.

---

## ‚è±Ô∏è 3. M√©tricas de Rendimiento

### 3.1 Tiempo de Procesamiento

Para procesamiento en batch:

$$
tiempo_{por\_texto} = \frac{tiempo_{total}}{n_{textos}}
$$

### 3.2 Tasa de √âxito

$$
tasa_{exito} = \frac{actualizaciones_{exitosas}}{opiniones_{procesadas}} \times 100\%
$$

---

## üî¢ 4. Resumen de Variables

| Variable | Descripci√≥n | Rango |
|----------|-------------|-------|
| `clasificacion` | Clase predicha | positivo, neutral, negativo |
| `confianza` | Certeza del modelo | [0, 1] |
| `pesos` | Distribuci√≥n de probabilidades | Suma = 1 |
| `score_positivo` | Ratio de palabras positivas | [0, 1] |
| `tiempo_ms` | Tiempo de procesamiento | milisegundos |

---

## üìù Notas T√©cnicas

1. **Truncamiento BERT**: Los textos se truncan a 512 tokens (l√≠mite de BERT).
2. **Batch Processing**: Se procesan m√∫ltiples textos simult√°neamente para eficiencia.
3. **Palabras Clave**: El categorizador usa ~200 palabras/frases por categor√≠a en espa√±ol mexicano.
4. **Dispositivos soportados**: CPU, CUDA (GPU NVIDIA), MPS (Apple Silicon).
5. **Diccionarios de palabras**: Cada categor√≠a tiene diccionarios separados de palabras positivas y negativas espec√≠ficas al contexto educativo universitario.
6. **B√∫squeda de coincidencias**: La b√∫squeda de palabras clave es case-insensitive y busca subcadenas.

---

*√öltima actualizaci√≥n: 2025-12-03*  
*Versi√≥n: 1.1.0*
